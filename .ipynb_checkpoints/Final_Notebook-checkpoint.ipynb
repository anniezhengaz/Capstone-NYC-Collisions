{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be963c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65fdcbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRASH DATE_CRASH TIME</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ON STREET NAME</th>\n",
       "      <th>CROSS STREET NAME</th>\n",
       "      <th>OFF STREET NAME</th>\n",
       "      <th>NUMBER OF PERSONS INJURED</th>\n",
       "      <th>...</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 2</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 3</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 4</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 5</th>\n",
       "      <th>COLLISION_ID</th>\n",
       "      <th>VEHICLE TYPE CODE 1</th>\n",
       "      <th>VEHICLE TYPE CODE 2</th>\n",
       "      <th>VEHICLE TYPE CODE 3</th>\n",
       "      <th>VEHICLE TYPE CODE 4</th>\n",
       "      <th>VEHICLE TYPE CODE 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-11 02:39:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITESTONE EXPRESSWAY</td>\n",
       "      <td>20 AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4455765</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-26 11:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QUEENSBORO BRIDGE UPPER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4513547</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-29 06:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THROGS NECK BRIDGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4541903</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Pick-up Truck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-11 09:35:00</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11208</td>\n",
       "      <td>40.667202</td>\n",
       "      <td>-73.866500</td>\n",
       "      <td>(40.667202, -73.8665)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1211      LORING AVENUE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4456314</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-14 08:13:00</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11233</td>\n",
       "      <td>40.683304</td>\n",
       "      <td>-73.917274</td>\n",
       "      <td>(40.683304, -73.917274)</td>\n",
       "      <td>SARATOGA AVENUE</td>\n",
       "      <td>DECATUR STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4486609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CRASH DATE_CRASH TIME   BOROUGH ZIP CODE   LATITUDE  LONGITUDE  \\\n",
       "0   2021-09-11 02:39:00       NaN      NaN        NaN        NaN   \n",
       "1   2022-03-26 11:45:00       NaN      NaN        NaN        NaN   \n",
       "2   2022-06-29 06:55:00       NaN      NaN        NaN        NaN   \n",
       "3   2021-09-11 09:35:00  BROOKLYN    11208  40.667202 -73.866500   \n",
       "4   2021-12-14 08:13:00  BROOKLYN    11233  40.683304 -73.917274   \n",
       "\n",
       "                  LOCATION           ON STREET NAME CROSS STREET NAME  \\\n",
       "0                      NaN    WHITESTONE EXPRESSWAY         20 AVENUE   \n",
       "1                      NaN  QUEENSBORO BRIDGE UPPER               NaN   \n",
       "2                      NaN       THROGS NECK BRIDGE               NaN   \n",
       "3    (40.667202, -73.8665)                      NaN               NaN   \n",
       "4  (40.683304, -73.917274)          SARATOGA AVENUE    DECATUR STREET   \n",
       "\n",
       "           OFF STREET NAME  NUMBER OF PERSONS INJURED  ...  \\\n",
       "0                      NaN                        2.0  ...   \n",
       "1                      NaN                        1.0  ...   \n",
       "2                      NaN                        0.0  ...   \n",
       "3  1211      LORING AVENUE                        0.0  ...   \n",
       "4                      NaN                        0.0  ...   \n",
       "\n",
       "   CONTRIBUTING FACTOR VEHICLE 2  CONTRIBUTING FACTOR VEHICLE 3  \\\n",
       "0                    Unspecified                            NaN   \n",
       "1                            NaN                            NaN   \n",
       "2                    Unspecified                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            NaN   \n",
       "\n",
       "   CONTRIBUTING FACTOR VEHICLE 4  CONTRIBUTING FACTOR VEHICLE 5  COLLISION_ID  \\\n",
       "0                            NaN                            NaN       4455765   \n",
       "1                            NaN                            NaN       4513547   \n",
       "2                            NaN                            NaN       4541903   \n",
       "3                            NaN                            NaN       4456314   \n",
       "4                            NaN                            NaN       4486609   \n",
       "\n",
       "   VEHICLE TYPE CODE 1  VEHICLE TYPE CODE 2 VEHICLE TYPE CODE 3  \\\n",
       "0                Sedan                Sedan                 NaN   \n",
       "1                Sedan                  NaN                 NaN   \n",
       "2                Sedan        Pick-up Truck                 NaN   \n",
       "3                Sedan                  NaN                 NaN   \n",
       "4                  NaN                  NaN                 NaN   \n",
       "\n",
       "  VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5  \n",
       "0                 NaN                 NaN  \n",
       "1                 NaN                 NaN  \n",
       "2                 NaN                 NaN  \n",
       "3                 NaN                 NaN  \n",
       "4                 NaN                 NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the dataset and merge Crash Date and Crash Time columns\n",
    "df = pd.read_csv('data/Motor_Vehicle_Collisions_-_Crashes.csv', low_memory=False, parse_dates=[['CRASH DATE', 'CRASH TIME']])\n",
    "\n",
    "#Initial look into dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0faaeb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1979921 entries, 0 to 1979920\n",
      "Data columns (total 28 columns):\n",
      " #   Column                         Dtype         \n",
      "---  ------                         -----         \n",
      " 0   CRASH DATE_CRASH TIME          datetime64[ns]\n",
      " 1   BOROUGH                        object        \n",
      " 2   ZIP CODE                       object        \n",
      " 3   LATITUDE                       float64       \n",
      " 4   LONGITUDE                      float64       \n",
      " 5   LOCATION                       object        \n",
      " 6   ON STREET NAME                 object        \n",
      " 7   CROSS STREET NAME              object        \n",
      " 8   OFF STREET NAME                object        \n",
      " 9   NUMBER OF PERSONS INJURED      float64       \n",
      " 10  NUMBER OF PERSONS KILLED       float64       \n",
      " 11  NUMBER OF PEDESTRIANS INJURED  int64         \n",
      " 12  NUMBER OF PEDESTRIANS KILLED   int64         \n",
      " 13  NUMBER OF CYCLIST INJURED      int64         \n",
      " 14  NUMBER OF CYCLIST KILLED       int64         \n",
      " 15  NUMBER OF MOTORIST INJURED     int64         \n",
      " 16  NUMBER OF MOTORIST KILLED      int64         \n",
      " 17  CONTRIBUTING FACTOR VEHICLE 1  object        \n",
      " 18  CONTRIBUTING FACTOR VEHICLE 2  object        \n",
      " 19  CONTRIBUTING FACTOR VEHICLE 3  object        \n",
      " 20  CONTRIBUTING FACTOR VEHICLE 4  object        \n",
      " 21  CONTRIBUTING FACTOR VEHICLE 5  object        \n",
      " 22  COLLISION_ID                   int64         \n",
      " 23  VEHICLE TYPE CODE 1            object        \n",
      " 24  VEHICLE TYPE CODE 2            object        \n",
      " 25  VEHICLE TYPE CODE 3            object        \n",
      " 26  VEHICLE TYPE CODE 4            object        \n",
      " 27  VEHICLE TYPE CODE 5            object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(7), object(16)\n",
      "memory usage: 423.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64fd57",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d25d71",
   "metadata": {},
   "source": [
    "### Changing DateTime Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3293235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename crash date column\n",
    "df.rename(columns = {'CRASH DATE_CRASH TIME':'CRASH DATE TIME'}, inplace = True)\n",
    "\n",
    "#Set to datetime index\n",
    "df.set_index('CRASH DATE TIME', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90101e2",
   "metadata": {},
   "source": [
    "The collisions within the last full 5 years will be considered only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b29c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter to crashes between 2018-2023\n",
    "df = df['2018-01-01':'2022-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b610b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01 00:00:00\n",
      "2022-12-31 23:50:00\n"
     ]
    }
   ],
   "source": [
    "#Sanity check of data time frame\n",
    "print (df.index.min())\n",
    "print (df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f55ab787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the datetime index in ascending order\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b728c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 'Collision ID' column from current location\n",
    "first_column = df.pop('COLLISION_ID')\n",
    "  \n",
    "#Insert column to desired location\n",
    "df.insert(0, 'COLLISION_ID', first_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b126b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for any duplicated rows\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f39263",
   "metadata": {},
   "source": [
    "### Borough Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e89278",
   "metadata": {},
   "source": [
    "The two of the five NYC boroughs with the largest populations will be analyzed: Queens and Brooklyn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7fc484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for collisions in Brooklyn and Queens borough\n",
    "df = df.loc[(df['BOROUGH'] == 'BROOKLYN') | (df['BOROUGH'] == 'QUEENS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34d5a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BROOKLYN', 'QUEENS'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check to ensure only two boroughs are included\n",
    "df['BOROUGH'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321a67af",
   "metadata": {},
   "source": [
    "### Dropping Columns/Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad8553a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111932\n",
      "112132\n",
      "193629\n"
     ]
    }
   ],
   "source": [
    "#Check for NaN values in street name columns\n",
    "print(df['ON STREET NAME'].isnull().sum())\n",
    "print(df['CROSS STREET NAME'].isnull().sum())\n",
    "print(df['OFF STREET NAME'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ffd62",
   "metadata": {},
   "source": [
    "There are 6 columns dedicated to where the collision took place. The 'LOCATION' column is to be dropped as it contains repetitive information from the 'LATITUDE' and 'LONGITUDE' columns. The columns regarding street name will be dropped as well due to the significant amount of missing values. \n",
    "\n",
    "There are a total of 8 columns dedicated to the number of people injured and killed as a result of the collision. The columns with the total number of injured and killed, whereas the columns specifying the type of person will be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2089037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6935\n"
     ]
    }
   ],
   "source": [
    "print(df['LOCATION'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d950847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop non-relevant and repetitive location columns\n",
    "df.drop(['LOCATION', 'ON STREET NAME', 'CROSS STREET NAME', 'OFF STREET NAME'], axis=1, inplace=True)\n",
    "\n",
    "#Drop repetitive injury/death columns\n",
    "df.drop(['NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1da35f",
   "metadata": {},
   "source": [
    "The focus will be on the Vehicle 1 as it is to be considered the primary vehicle of the collision. The columns for the contributing factor and vehicle type code for vehicles 2-5 have a significant amount of missing values and therefore will be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop additional contributing factor vehicle columns\n",
    "df.drop(['CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5'], axis=1, inplace=True)\n",
    "\n",
    "#Drop additional vehicle type columns\n",
    "df.drop(['VEHICLE TYPE CODE 2', 'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ffc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NaN values from columns of contributing factors\n",
    "df = df.dropna(subset=['CONTRIBUTING FACTOR VEHICLE 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78de635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out the collisions with Unspecified contributing factor\n",
    "df = df[df['CONTRIBUTING FACTOR VEHICLE 1'] != 'Unspecified']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11973cb6",
   "metadata": {},
   "source": [
    "#### Number of Persons Injured & Number of Persons Killed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfc73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for NaN values in injury/death columns\n",
    "print(df['NUMBER OF PERSONS KILLED'].isnull().sum())\n",
    "print(df['NUMBER OF PERSONS INJURED'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02de265",
   "metadata": {},
   "source": [
    "Since there were only 2 collisions with missing values from the 'NUMBER OF PERSONS KILLED' column and only 3 from the 'NUMBER OF PERSONS INJURED', these rows will be dropped.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e53239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NaN values from injury/death columns\n",
    "df = df.dropna(subset=['NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED'])\n",
    "\n",
    "#Sanity check to verify no more NaN values\n",
    "print(df['NUMBER OF PERSONS KILLED'].isnull().sum())\n",
    "print(df['NUMBER OF PERSONS INJURED'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c4ba2",
   "metadata": {},
   "source": [
    "#### Latitude and Longitude\n",
    "The Latitude and Longitude columns will be kept to ensure the location of the collisions can be mapped using Folium. First, we must verify if there are any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e718d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for NaN values in Latitude and Longitude columns\n",
    "print(df['LATITUDE'].isnull().sum())\n",
    "print(df['LONGITUDE'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e493354",
   "metadata": {},
   "source": [
    "Since there are less than 5,000 rows missing values for Latitude and Longitude, these rows will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15388ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop missing values from Latitude and Longitude columns\n",
    "df = df.dropna(subset=['LATITUDE', 'LONGITUDE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90afca02",
   "metadata": {},
   "source": [
    "Now that we know there are no duplicate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b13e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the minimum/maximum values of Latitude\n",
    "df['LATITUDE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the minimum/maximum values of Longitude\n",
    "df['LONGITUDE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many collisions have a Latitude of 0\n",
    "df[df['LATITUDE'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many collisions have a Longitude of 0\n",
    "df[df['LONGITUDE'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae1f961",
   "metadata": {},
   "source": [
    "There are 161 rows with both Longitude and Latitude of 0. Looking at the head and tail, we can assume these's are all the same 161 rows. To ensure our data is well-rounded with complete and accurate values, let's drop the collisions with a Longitude and Latitude of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for collisions that do NOT have Longitude and Latitude of 0\n",
    "df = df[df['LONGITUDE'] != 0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a651cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check how many collisions have a Longitude of 0\n",
    "df[df['LONGITUDE'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e54eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check how many collisions have a Latitude of 0\n",
    "df[df['LATITUDE'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb857b",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check rows with missing zip code\n",
    "df[df['ZIP CODE'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbce27",
   "metadata": {},
   "source": [
    "There are 71 missing values from the Zip Code column, however, we see that numerous rows have the same latitude and longitude. Let's impute those rows instead of dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e68658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary that corresponds the Latitude, Longitude with the correct Zip Code\n",
    "zipcode_dict = {(40.72010, -73.79038): 11432,\n",
    "                (40.76092, -73.82680): 11354,\n",
    "                (40.72013, -73.79038): 11433,\n",
    "                (40.75089, -73.93663): 11101,\n",
    "                (40.724792, -73.722916): 11426,\n",
    "                (40.713050, -73.916990): 11385,\n",
    "                (40.711930, -73.919365): 11385,\n",
    "                (40.724792, -73.722916): 11426,\n",
    "                (40.707447, -73.903870): 11385,\n",
    "                (40.707485, -73.918365): 11385,\n",
    "                (40.733120, -73.727900): 11426,\n",
    "                (40.719124, -73.791405): 11432, \n",
    "                (40.606260, -73.744170): 11691,\n",
    "                (40.707317, -73.903595): 11385,\n",
    "                (40.695072, -73.990100): 11201,}\n",
    "\n",
    "# use the map function to update the 'zipcode' column based on the dictionary\n",
    "df['ZIP CODE'] = df.apply(lambda row: zipcode_dict.get((row['LATITUDE'], row['LONGITUDE']), row['ZIP CODE']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71151bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check to confirm there's no more NaN values in Zip Code column\n",
    "df[df['ZIP CODE'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9bdee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check to confirm zipcode was imputed for indexed row\n",
    "#df[df.index.isin(['2018-01-18 17:20:00'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check to confirm zipcode was imputed for indexed row\n",
    "df.loc[[4050]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc2df8",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa8069",
   "metadata": {},
   "source": [
    "#### Contributing Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58da3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review the contributing factors\n",
    "df['CONTRIBUTING FACTOR VEHICLE 1'].value_counts(sort=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d62adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the unique values of contributing factors for vehicle 1\n",
    "df['CONTRIBUTING FACTOR VEHICLE 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create duplicate columns of contributing factor columns for categorizing\n",
    "df['CONTRIBUTING CATEGORY V1'] = df['CONTRIBUTING FACTOR VEHICLE 1']\n",
    "\n",
    "#Replace value with correct spelling of 'Illness'\n",
    "df['CONTRIBUTING FACTOR VEHICLE 1'].replace('Illnes', 'Illness', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace specific contributing factor to a more generalized category in Contributing Category Vehicle 1\n",
    "df['CONTRIBUTING CATEGORY V1'].replace(('Driver Inattention/Distraction', 'Driver Inexperience', \n",
    "                                        'Reaction to Uninvolved Vehicle', 'Aggressive Driving/Road Rage', \n",
    "                                        'Eating or Drinking'), ('Driver Error'), inplace=True)\n",
    "\n",
    "df['CONTRIBUTING CATEGORY V1'].replace(('Tire Failure/Inadequate', 'Headlights Defective', 'Steering Failure', \n",
    "                                        'Brakes Defective', 'Accelerator Defective', 'Tow Hitch Defective', \n",
    "                                        'Other Lighting Defects', 'Tinted Windows', 'Vehicle Vandalism', \n",
    "                                        'Windshield Inadequate'), ('Vehicle Defects'), inplace=True)\n",
    "\n",
    "df['CONTRIBUTING CATEGORY V1'].replace(('Failure to Yield Right-of-Way','Passing or Lane Usage Improper', \n",
    "                                        'Unsafe Lane Changing','Failure to Keep Right', \n",
    "                                        'Traffic Control Disregarded','Passing Too Closely', \n",
    "                                        'Backing Unsafely', 'Unsafe Speed', 'Following Too Closely', \n",
    "                                        'Turning Improperly'), ('Moving Violation'), inplace=True)\n",
    "\n",
    "df['CONTRIBUTING CATEGORY V1'].replace(('Glare', 'Obstruction/Debris', 'View Obstructed/Limited'), \n",
    "                                       ('Environmental Factors'), inplace=True)\n",
    "\n",
    "df['CONTRIBUTING CATEGORY V1'].replace(('Cell Phone (hand-Held)', 'Texting', 'Using On Board Navigation Device', \n",
    "                                        'Other Electronic Device', 'Listening/Using Headphones', \n",
    "                                        'Cell Phone (hands-free)'), ('Internal Electronics Usage'), inplace=True)\n",
    "\n",
    "df['CONTRIBUTING CATEGORY V1'].replace(('Illnes', 'Illness', 'Drugs (illegal)', 'Fell Asleep', 'Fatigued/Drowsy', \n",
    "                                        'Lost Consciousness', 'Physical Disability', 'Alcohol Involvement', \n",
    "                                        'Prescription Medication'), ('Bodily Impairment'), inplace=True)\n",
    "\n",
    "df['CONTRIBUTING CATEGORY V1'].replace(('Traffic Control Device Improper/Non-Working', 'Pavement Slippery', \n",
    "                                        'Pavement Defective', 'Shoulders Defective/Improper', \n",
    "                                        'Lane Marking Improper/Inadequate'), ('Road Conditions'), inplace=True)\n",
    "\n",
    "df['CONTRIBUTING CATEGORY V1'].replace(('Driverless/Runaway Vehicle', 'Other Vehicular', 'Oversized Vehicle'), \n",
    "                                       ('Third-Party (Vehicular)'), inplace=True)\n",
    "\n",
    "df['CONTRIBUTING CATEGORY V1'].replace(('Animals Action', \n",
    "                                        'Pedestrian/Bicyclist/Other Pedestrian Error/Confusion'), \n",
    "                                       ('Third-Party (Non-Vehicular)'), inplace=True)\n",
    "\n",
    "df['CONTRIBUTING CATEGORY V1'].replace(('Passenger Distraction', 'Outside Car Distraction'), \n",
    "                                       ('Other Distractions'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check to confirm only 10 categories\n",
    "df['CONTRIBUTING CATEGORY V1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da7655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert columns from float to integers\n",
    "df = df.astype({'ZIP CODE':'int64', 'NUMBER OF PERSONS INJURED':'int64', 'NUMBER OF PERSONS KILLED':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0178824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to datetime datatype\n",
    "df['CRASH DATE TIME'] = pd.to_datetime(df['CRASH DATE TIME']) #changing to datetime datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d04b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop remaining NaN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b72ca6",
   "metadata": {},
   "source": [
    "#### Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8325a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Season column\n",
    "## Months 3-5 = Spring\n",
    "## Months 6-8 = Summer\n",
    "## Months 9-11 = Autumn\n",
    "## Months 12-2 = Winter\n",
    "\n",
    "df['SEASON'] = np.where(((df[\"CRASH DATE TIME\"].dt.month >= 3) & (df[\"CRASH DATE TIME\"].dt.month <= 5)), 'Spring',\n",
    "                          np.where(((df[\"CRASH DATE TIME\"].dt.month >= 6) & (df[\"CRASH DATE TIME\"].dt.month <= 8)), 'Summer',\n",
    "                                  np.where(((df[\"CRASH DATE TIME\"].dt.month >= 9) & (df[\"CRASH DATE TIME\"].dt.month <= 11)), 'Autumn', 'Winter')))\n",
    "\n",
    "df['SEASON'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94c495",
   "metadata": {},
   "source": [
    "#### Time of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c99b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the bins\n",
    "bins=[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 24]\n",
    "\n",
    "#Custom labels for time of day/hour intervals\n",
    "labels=['Late Night', 'Early Morning', 'Dawn', 'Early AM', 'Morning', 'Late Morning', 'Early Afternoon', \n",
    "        'Afternoon', 'Evening', 'Night']\n",
    "\n",
    "#Add the bins to the dataframe\n",
    "df['TIME OF DAY'] = pd.cut(df['CRASH DATE TIME'].dt.hour, bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358d765",
   "metadata": {},
   "source": [
    "#### Is Rush Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set to datetime index\n",
    "df.set_index('CRASH DATE TIME', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb683bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and join dataframes indicating rush hour traffic\n",
    "rush_hour = pd.concat([df.between_time('6:00', '9:00'), df.between_time('16:00', '19:00')])\n",
    "\n",
    "#Create new column indicating if rush hour -- return True if index is in rush_hour, False if not\n",
    "df['IS RUSH HOUR'] = df.index.isin(rush_hour.index)\n",
    "\n",
    "#Sanity check to confirm there are True/False values\n",
    "df['IS RUSH HOUR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026887fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1129dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6efdf29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ab071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744203e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59295f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022aed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3f881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280d32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dca489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e6731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24114d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea1c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e6b09c",
   "metadata": {},
   "source": [
    "Export smaller dataset that can be pushed to GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cb6bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export 2018-2023 Queens and Brooklyn dataset as a .csv as main dataset\n",
    "#df.to_csv('data/Motor_Vehicle_Collisions_QuBr_2018-2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export as a .csv as final cleaned dataset\n",
    "#df.to_csv('data/Final_Motor_Vehicle_Collisions_QuBr_2018-2023_V1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
